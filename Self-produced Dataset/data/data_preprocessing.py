# -*- coding: utf-8 -*-
"""Data Preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jj0UYfCTOMsJMLHuEEL6mvo7PuThBaRu

# Data Description

Even though the data is pretty clean, there are still some inconsistencies across the images:
- The letters are not properly centered to the image
- Some letters have thicker lines compared to others, particularly letter Ã¢
- There are some minor noises in the background of the images.

As a result, we need to perform some pre-processing to improve the quality of the dataset. There are 5 steps in this order:

1. **Noise Reduction**: Given that our images are pretty clean, we will apply Gaussian Blurring as the image smoothing technique to remove small quantities of noise.
2. **Binarization**: Convert the original RGB color channels into a binary-color channel, which means that each pixel only holds either two values (0 or 1).
3. **Re-centering**: Recenter the centroid of the letter to the center of the image.
4. **Skeletonization**: Thin the letters to its basic form such that the width of the line is only 1-2 pixels. This helps remain the structure of the image. (_I'm still a bit skeptical about this part so I will leave it about the datapreprocessing first and if the performance is not as I expected, I'll add it later to compare_)
5. **Image Resizing**: 64x64 pixels

## Import Libraries
"""

# General
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# File reading
import os
from google.colab import drive
from typing import List

# Image Preprocessing
import os
import cv2 as cv
from google.colab.patches import cv2_imshow
from skimage.morphology import skeletonize, thin
from skimage import data
from skimage.util import invert

drive.mount('/content/gdrive')

"""## Data Preprocessing"""

class DataPreprocessing:
    def __init__(self, image_path: str = None, output_size=(None, None), crop_image: bool = True):
        self.image_path = image_path
        self.output_size = output_size
        self.crop_image = crop_image

    def load_image(self):
        img = cv.imread(self.image_path)
        if img is None:
            raise ValueError(f"Image could not be loaded from: {self.image_path}")
        return img

    def noise_reduction(self, sigma_x=33, sigma_y=33):
        """Reduce noise using Gaussian blur after converting to grayscale."""
        img = self.load_image()
        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
        blur = cv.GaussianBlur(gray, (0, 0), sigmaX=sigma_x, sigmaY=sigma_y)
        return gray, blur

    def binarize(self, kernel_size=(3, 3)):
        """Binarize image using Gaussian blur and Otsu's thresholding."""
        gray, blur = self.noise_reduction()
        divide = cv.divide(gray, blur, scale=255)
        _, thresh = cv.threshold(divide, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)
        kernel = cv.getStructuringElement(cv.MORPH_RECT, kernel_size)
        morph = cv.morphologyEx(thresh, cv.MORPH_CLOSE, kernel, iterations=1)
        return morph

    def crop(self, img):
        if len(img.shape) == 2:
          gray = self.binarize()
        else:
          gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
        _, thresh = cv.threshold(gray, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)
        contours, _ = cv.findContours(thresh, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)

        # Handle cases where there are no contours
        if not contours:
            return img  # Return original image if no contours found

        # Find the bounding box coordinates from contours
        x_min = int(np.min([np.min(contour[:, :, 0]) for contour in contours]))
        y_min = int(np.min([np.min(contour[:, :, 1]) for contour in contours]))
        x_max = int(np.max([np.max(contour[:, :, 0]) for contour in contours]))
        y_max = int(np.max([np.max(contour[:, :, 1]) for contour in contours]))

        # Crop the image using the bounding box
        cropped_img = img[y_min:y_max, x_min:x_max]

        return cropped_img

    def resize(self, output_size=None, normalize=True):
        """Resize the image to the specified size and normalize the pixel values if needed."""
        if output_size is None:
            output_size = self.output_size
        img = self.binarize()  # Binarize the image before cropping
        if self.crop_image:  # Check if cropping is enabled
          img = self.crop(img)  # Call the cropping function
        img = cv.resize(img, output_size)  # Resize to the target size
        if normalize:
            img = cv.normalize(img, None, 0, 255, cv.NORM_MINMAX).astype(np.uint8)
        return img

    def process(self, return_steps=False, output_size=None, normalize=True):
        """Process the image through all steps with optional output of intermediate results."""
        result = self.resize(output_size=output_size, normalize=normalize)
        if return_steps:
            return {
                "noise_reduction": self.noise_reduction(),
                "binarization": self.binarize(),
                "crop_image": self.crop_image(self.binarize()),  # Pass the binarized image
                "final_result": result
            }
        return result

"""## Feature Engineering"""

def preprocessed_df(df, output_size=None, crop_image=True):
    """
    Preprocesses a DataFrame of image data.

    Args:
        df (pd.DataFrame): DataFrame containing image file paths and labels.
        output_size (tuple, optional): Desired output size for images. Defaults to None.
        crop_image (bool, optional): Whether to crop images. Defaults to None.

    Returns:
        pd.DataFrame: DataFrame with preprocessed images and labels.
    """
    preprocessed_data = []
    for index, row in df.iterrows():
        image_path = row['image_file']
        img = DataPreprocessing(image_path=image_path, output_size=output_size, crop_image=crop_image)
        processed_img = img.process()
        preprocessed_data.append((processed_img, row['label']))

    df = pd.DataFrame(preprocessed_data, columns=['image', 'label'])
    return df

def raw_pixel_features(df, rows=None, cols=None):
    all_features = []

    for index in df.index:
      image_data = df.loc[index, 'image']
      all_features.append(image_data.flatten()/255.0)

    pixel_columns = [f'pixel{i}_{j}' for i in range(rows) for j in range(cols)]
    feature_set = pd.DataFrame(all_features, columns=pixel_columns)
    feature_set['label'] = df['label']

    return feature_set

train_set = pd.read_csv("/content/gdrive/MyDrive/24-25 Academic Year/CS156/First Pipeline/Preprocessed Data/handwritten_train_set.csv")
test_set = pd.read_csv("/content/gdrive/MyDrive/24-25 Academic Year/CS156/First Pipeline/Preprocessed Data/handwritten_test_set.csv")

"""### Without Cropping Images"""

fs0_64 = preprocessed_df(train_set, output_size=(64, 64), crop_image=False)
fs0_28 = preprocessed_df(train_set, output_size=(28, 28), crop_image=False)
fs0_10 = preprocessed_df(train_set, output_size=(10, 10), crop_image=False)

fs0_64 = raw_pixel_features(fs0_64, rows=64, cols=64)
fs0_28 = raw_pixel_features(fs0_28, rows=28, cols=28)
fs0_10 = raw_pixel_features(fs0_10, rows=10, cols=10)

fs0_64.to_csv("/content/gdrive/MyDrive/24-25 Academic Year/CS156/First Pipeline/Preprocessed Data/feature_train_set_064.csv", index=False)
fs0_28.to_csv("/content/gdrive/MyDrive/24-25 Academic Year/CS156/First Pipeline/Preprocessed Data/feature_train_set_028.csv", index=False)
fs0_10.to_csv("/content/gdrive/MyDrive/24-25 Academic Year/CS156/First Pipeline/Preprocessed Data/feature_train_set_010.csv", index=False)

pd.read_csv("/content/gdrive/MyDrive/24-25 Academic Year/CS156/First Pipeline/Preprocessed Data/feature_train_set_064.csv")

fs0_test_64 = preprocessed_df(test_set, output_size=(64, 64), crop_image=False)
fs0_test_28 = preprocessed_df(test_set, output_size=(28, 28), crop_image=False)
fs0_test_10 = preprocessed_df(test_set, output_size=(10, 10), crop_image=False)

fs0_test_64 = raw_pixel_features(fs0_test_64, rows=64, cols=64)
fs0_test_28 = raw_pixel_features(fs0_test_28, rows=28, cols=28)
fs0_test_10 = raw_pixel_features(fs0_test_10, rows=10, cols=10)

fs0_test_64.to_csv("/content/gdrive/MyDrive/24-25 Academic Year/CS156/First Pipeline/Preprocessed Data/feature_set_test_064.csv", index=False)
fs0_test_28.to_csv("/content/gdrive/MyDrive/24-25 Academic Year/CS156/First Pipeline/Preprocessed Data/feature_set_test_028.csv", index=False)
fs0_test_10.to_csv("/content/gdrive/MyDrive/24-25 Academic Year/CS156/First Pipeline/Preprocessed Data/feature_set_test_010.csv", index=False)

"""### With Cropping Images"""

fs1_64 = preprocessed_df(train_set, output_size=(64, 64), crop_image=True)
fs1_28 = preprocessed_df(train_set, output_size=(28, 28), crop_image=True)
fs1_10 = preprocessed_df(train_set, output_size=(10, 10), crop_image=True)

img = fs1_64.iloc[0]['image']
plt.imshow(img, cmap='gray')
plt.show()

fs1_64_p = raw_pixel_features(fs1_64, rows=64, cols=64)
fs1_28_p = raw_pixel_features(fs1_28, rows=28, cols=28)
fs1_10_p = raw_pixel_features(fs1_10, rows=10, cols=10)

fs1_64_p.to_csv("/content/gdrive/MyDrive/24-25 Academic Year/CS156/First Pipeline/Preprocessed Data/feature_train_set_164.csv", index=False)
fs1_28_p.to_csv("/content/gdrive/MyDrive/24-25 Academic Year/CS156/First Pipeline/Preprocessed Data/feature_train_set_128.csv", index=False)
fs1_10_p.to_csv("/content/gdrive/MyDrive/24-25 Academic Year/CS156/First Pipeline/Preprocessed Data/feature_train_set_110.csv", index=False)

df = pd.read_csv("/content/gdrive/MyDrive/24-25 Academic Year/CS156/First Pipeline/Preprocessed Data/feature_train_set_164.csv")
df

fs1_test_64 = preprocessed_df(test_set, output_size=(64, 64), crop_image=True)
fs1_test_28 = preprocessed_df(test_set, output_size=(28, 28), crop_image=True)
fs1_test_10 = preprocessed_df(test_set, output_size=(10, 10), crop_image=True)

fs1_test_64_p = raw_pixel_features(fs1_test_64, rows=64, cols=64)
fs1_test_28_p = raw_pixel_features(fs1_test_28, rows=28, cols=28)
fs1_test_10_p = raw_pixel_features(fs1_test_10, rows=10, cols=10)

fs1_test_64_p.to_csv("/content/gdrive/MyDrive/24-25 Academic Year/CS156/First Pipeline/Preprocessed Data/feature_set_test_164.csv")
fs1_test_28_p.to_csv("/content/gdrive/MyDrive/24-25 Academic Year/CS156/First Pipeline/Preprocessed Data/feature_set_test_128.csv")
fs1_test_10_p.to_csv("/content/gdrive/MyDrive/24-25 Academic Year/CS156/First Pipeline/Preprocessed Data/feature_set_test_110.csv")